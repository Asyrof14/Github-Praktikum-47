{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "294345c4-b21a-4b5d-a9ab-5788c50d0338",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: findspark in ./anaconda3/envs/asyrof/lib/python3.13/site-packages (2.0.1)\n",
      "Requirement already satisfied: pyspark in ./anaconda3/envs/asyrof/lib/python3.13/site-packages (4.0.1)\n",
      "Requirement already satisfied: numpy in ./anaconda3/envs/asyrof/lib/python3.13/site-packages (2.3.4)\n",
      "Requirement already satisfied: py4j==0.10.9.9 in ./anaconda3/envs/asyrof/lib/python3.13/site-packages (from pyspark) (0.10.9.9)\n"
     ]
    }
   ],
   "source": [
    "!pip install findspark\n",
    "!pip install pyspark numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5add8ecc-ab20-4b4b-abc0-321ceddf3ffa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/12/02 19:38:01 WARN Utils: Your hostname, asyrof-VirtualBox resolves to a loopback address: 127.0.1.1; using 10.0.2.15 instead (on interface enp0s3)\n",
      "25/12/02 19:38:01 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/12/02 19:38:01 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "25/12/02 19:38:16 WARN Instrumentation: [42b2acc7] regParam is zero, which might cause numerical instability and overfitting.\n",
      "25/12/02 19:38:21 WARN InstanceBuilder: Failed to load implementation from:dev.ludovic.netlib.blas.JNIBLAS\n",
      "25/12/02 19:38:21 WARN InstanceBuilder: Failed to load implementation from:dev.ludovic.netlib.lapack.JNILAPACK\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: [4.000000000000004]\n",
      "Intercept: -5.076362500572609e-14\n"
     ]
    }
   ],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "# Initialize Spark Session\n",
    "spark = SparkSession.builder.appName(\"AdvancedML\").getOrCreate()\n",
    "\n",
    "# Sample data for regression\n",
    "# Format: (ID, Feature, Label)\n",
    "data = [(1, 5.0, 20.0), (2, 10.0, 40.0), (3, 15.0, 60.0)]\n",
    "columns = [\"ID\", \"Feature\", \"Label\"]\n",
    "df = spark.createDataFrame(data, columns)\n",
    "\n",
    "# Prepare features using VectorAssembler\n",
    "# Spark ML mengharuskan fitur input digabung menjadi satu kolom vektor\n",
    "assembler = VectorAssembler(inputCols=[\"Feature\"], outputCol=\"Features\")\n",
    "df = assembler.transform(df)\n",
    "\n",
    "# Train linear regression model\n",
    "lr = LinearRegression(featuresCol=\"Features\", labelCol=\"Label\")\n",
    "model = lr.fit(df)\n",
    "\n",
    "# Display coefficients and intercept\n",
    "print(f\"Coefficients: {model.coefficients}\")\n",
    "print(f\"Intercept: {model.intercept}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "99e1d0c0-024f-4ae5-a894-c99bb43d1d73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: [67.77891676420779]\n",
      "Intercept: -152.51530779434026\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    "\n",
    "data = [(1, 2.0, 0), (2, 2.5, 1), (3, 1.5, 0), (4, 3.0, 1)]\n",
    "columns = [\"ID\", \"Feature\", \"Label\"]\n",
    "df = spark.createDataFrame(data, columns)\n",
    "\n",
    "assembler = VectorAssembler(inputCols=[\"Feature\"], outputCol=\"Features\")\n",
    "df = assembler.transform(df)\n",
    "\n",
    "lr = LogisticRegression(featuresCol=\"Features\", labelCol=\"Label\")\n",
    "model = lr.fit(df)\n",
    "\n",
    "print(f\"Coefficients: {model.coefficients}\")\n",
    "print(f\"Intercept: {model.intercept}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "62b8c1ab-bb5f-46c4-b3fc-0e31ea4a2d1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster Centers: \n",
      "[12.5 12.5]\n",
      "[3. 3.]\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.clustering import KMeans\n",
    "from pyspark.ml.linalg import Vectors\n",
    "\n",
    "data = [(1, Vectors.dense([1.0, 1.0])), (2, Vectors.dense([5.0, 5.0])), \n",
    "        (3, Vectors.dense([10.0, 10.0])), (4, Vectors.dense([15.0, 15.0]))]\n",
    "columns = [\"ID\", \"Features\"]\n",
    "df = spark.createDataFrame(data, columns)\n",
    "\n",
    "kmeans = KMeans(featuresCol=\"Features\", k=2)\n",
    "model = kmeans.fit(df)\n",
    "\n",
    "centers = model.clusterCenters()\n",
    "print(\"Cluster Centers: \")\n",
    "for center in centers:\n",
    "    print(center)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2137781d-20f8-4cdf-95c9-eca6b563325c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- app_id: integer (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- date_release: date (nullable = true)\n",
      " |-- win: boolean (nullable = true)\n",
      " |-- mac: boolean (nullable = true)\n",
      " |-- linux: boolean (nullable = true)\n",
      " |-- rating: string (nullable = true)\n",
      " |-- positive_ratio: integer (nullable = true)\n",
      " |-- user_reviews: double (nullable = true)\n",
      " |-- price_final: double (nullable = true)\n",
      " |-- price_original: double (nullable = true)\n",
      " |-- discount: double (nullable = true)\n",
      " |-- steam_deck: boolean (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "# Initialize Spark Session (Wajib jika belum inisialisasi)\n",
    "try:\n",
    "    spark\n",
    "except NameError:\n",
    "    spark = SparkSession.builder.appName(\"MLlibHomework\").getOrCreate()\n",
    "\n",
    "file_path = \"file:///home/asyrof/Downloads/games.csv\"\n",
    "\n",
    "# Load Dataset games.csv\n",
    "df_games = spark.read.csv(file_path, header=True, inferSchema=True)\n",
    "\n",
    "# Data Cleaning: Hapus baris yang memiliki nilai null di kolom penting\n",
    "df_games = df_games.na.drop(subset=[\"price_final\", \"user_reviews\", \"positive_ratio\", \"rating\"])\n",
    "\n",
    "# Konversi tipe data numerik jika diperlukan (untuk menjamin perhitungan ML)\n",
    "df_games = df_games.withColumn(\"user_reviews\", col(\"user_reviews\").cast(\"double\"))\n",
    "df_games = df_games.withColumn(\"price_final\", col(\"price_final\").cast(\"double\"))\n",
    "\n",
    "df_games.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8212953b-4037-48c3-9f13-35a09c22cd51",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/12/02 19:40:43 WARN Instrumentation: [1532d316] regParam is zero, which might cause numerical instability and overfitting.\n",
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Hasil Linear Regression ---\n",
      "Coefficients (Pengaruh Review & Ratio): [7.621025326749801e-06,-0.005823325571842184]\n",
      "Intercept (Harga Dasar): 9.012476896394295\n",
      "+-----------+------------------+\n",
      "|price_final|        prediction|\n",
      "+-----------+------------------+\n",
      "|       4.99| 8.565824317717862|\n",
      "|       4.99| 8.562742697844717|\n",
      "|       9.99| 8.686038510196534|\n",
      "|       9.99| 8.583495612031664|\n",
      "|       10.0|12.825664735383562|\n",
      "+-----------+------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "# 1. Feature Engineering\n",
    "# Menggabungkan 'user_reviews' dan 'positive_ratio' menjadi satu kolom vektor 'Features'\n",
    "assembler_lr = VectorAssembler(\n",
    "    inputCols=[\"user_reviews\", \"positive_ratio\"], \n",
    "    outputCol=\"Features\"\n",
    ")\n",
    "df_lr = assembler_lr.transform(df_games)\n",
    "\n",
    "# 2. Split Data (70% Training, 30% Testing)\n",
    "train_data, test_data = df_lr.randomSplit([0.7, 0.3], seed=42)\n",
    "\n",
    "# 3. Modeling\n",
    "# LabelCol adalah target yang ingin diprediksi (Harga)\n",
    "lr = LinearRegression(featuresCol=\"Features\", labelCol=\"price_final\")\n",
    "lr_model = lr.fit(train_data)\n",
    "\n",
    "# 4. Evaluasi\n",
    "print(\"--- Hasil Linear Regression ---\")\n",
    "print(f\"Coefficients (Pengaruh Review & Ratio): {lr_model.coefficients}\")\n",
    "print(f\"Intercept (Harga Dasar): {lr_model.intercept}\")\n",
    "\n",
    "# Melihat hasil prediksi pada data test\n",
    "predictions = lr_model.transform(test_data)\n",
    "predictions.select(\"price_final\", \"prediction\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "330a1cae-730f-40e8-bd01-cd164ef4b794",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Hasil Logistic Regression ---\n",
      "+-----------+------------+-----------+----------+\n",
      "|price_final|user_reviews|label_class|prediction|\n",
      "+-----------+------------+-----------+----------+\n",
      "|       4.99|      1757.0|          0|       1.0|\n",
      "|       4.99|     10522.0|          1|       1.0|\n",
      "|       9.99|     10654.0|          0|       1.0|\n",
      "|       10.0|    574470.0|          1|       1.0|\n",
      "|       4.99|      1282.0|          1|       1.0|\n",
      "+-----------+------------+-----------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Area Under ROC (AUC): 0.5309\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.sql.functions import when\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "\n",
    "# 1. Label Engineering\n",
    "# Kita buat kolom baru 'is_high_rated': 1 jika positive_ratio > 80, 0 jika tidak.\n",
    "df_log = df_games.withColumn(\"label_class\", when(df_games[\"positive_ratio\"] > 80, 1).otherwise(0))\n",
    "\n",
    "# 2. Feature Engineering\n",
    "# Menggunakan 'price_final' dan 'user_reviews' sebagai fitur prediksi\n",
    "assembler_log = VectorAssembler(\n",
    "    inputCols=[\"price_final\", \"user_reviews\"], \n",
    "    outputCol=\"Features\"\n",
    ")\n",
    "df_log_final = assembler_log.transform(df_log)\n",
    "\n",
    "# 3. Split Data\n",
    "train_log, test_log = df_log_final.randomSplit([0.8, 0.2], seed=42)\n",
    "\n",
    "# 4. Modeling\n",
    "log_reg = LogisticRegression(featuresCol=\"Features\", labelCol=\"label_class\")\n",
    "log_model = log_reg.fit(train_log)\n",
    "\n",
    "# 5. Evaluasi\n",
    "print(\"\\n--- Hasil Logistic Regression ---\")\n",
    "predictions_log = log_model.transform(test_log)\n",
    "predictions_log.select(\"price_final\", \"user_reviews\", \"label_class\", \"prediction\").show(5)\n",
    "\n",
    "evaluator_log = BinaryClassificationEvaluator(labelCol=\"label_class\")\n",
    "auc = evaluator_log.evaluate(predictions_log)\n",
    "print(f\"Area Under ROC (AUC): {auc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5f15b56d-d3ea-458c-9365-5c93cc53a543",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Hasil K-Means Clustering ---\n",
      "Pusat Cluster (Centroids - [Price, Reviews]):\n",
      "Cluster 0: [   8.61745314 1270.21603761]\n",
      "Cluster 1: [1.50000e+01 7.49446e+06]\n",
      "Cluster 2: [1.36071429e+01 7.40574786e+05]\n",
      "\n",
      "Silhouette Score: 0.9992\n",
      "+--------------------+-----------+------------+----------+\n",
      "|               title|price_final|user_reviews|prediction|\n",
      "+--------------------+-----------+------------+----------+\n",
      "|Prince of Persia:...|       9.99|      2199.0|         0|\n",
      "|BRINK: Agents of ...|       2.99|        21.0|         0|\n",
      "|Monaco: What's Yo...|      14.99|      3722.0|         0|\n",
      "|  Escape Dead Island|      14.99|       873.0|         0|\n",
      "|Dungeon of the EN...|      11.99|      8784.0|         0|\n",
      "+--------------------+-----------+------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.clustering import KMeans\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.evaluation import ClusteringEvaluator\n",
    "\n",
    "# 1. Feature Engineering\n",
    "# Kita hanya menggunakan fitur numerik untuk clustering\n",
    "assembler_km = VectorAssembler(\n",
    "    inputCols=[\"price_final\", \"user_reviews\"], \n",
    "    outputCol=\"Features\"\n",
    ")\n",
    "df_km = assembler_km.transform(df_games)\n",
    "\n",
    "# 2. Modeling\n",
    "# k=3: Kita ingin mencari 3 tipe kelompok game (misal: Murah-Sepi, Mahal-Populer, dsb)\n",
    "# PERBAIKAN ERROR: Menggunakan featuresCol=\"Features\" (dengan F kapital)\n",
    "kmeans = KMeans(featuresCol=\"Features\", k=3)\n",
    "model_km = kmeans.fit(df_km)\n",
    "\n",
    "# 3. Hasil Clustering\n",
    "predictions_km = model_km.transform(df_km)\n",
    "centers = model_km.clusterCenters()\n",
    "\n",
    "# 4. Evaluasi (Silhouette Score)\n",
    "# PERBAIKAN ERROR: Menggunakan featuresCol=\"Features\" (dengan F kapital)\n",
    "evaluator_km = ClusteringEvaluator(featuresCol=\"Features\")\n",
    "silhouette = evaluator_km.evaluate(predictions_km)\n",
    "\n",
    "print(\"\\n--- Hasil K-Means Clustering ---\")\n",
    "print(\"Pusat Cluster (Centroids - [Price, Reviews]):\")\n",
    "for i, center in enumerate(centers):\n",
    "    print(f\"Cluster {i}: {center}\")\n",
    "print(f\"\\nSilhouette Score: {silhouette:.4f}\")\n",
    "\n",
    "# Menampilkan game masuk ke cluster mana\n",
    "predictions_km.select(\"title\", \"price_final\", \"user_reviews\", \"prediction\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ff3f475-73b4-4a61-aeb2-cf4371379775",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:asyrof]",
   "language": "python",
   "name": "conda-env-asyrof-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
